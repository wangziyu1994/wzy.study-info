## 1.MySQL执行计划

#### 1. explain +SQL  显示SQL的执行计划

1. id

	id相同，说明是同一级查询，从上往下，依次执行。

	id不同, id越大说明查询的优先级越高

	id相同不同的混合。 id相同的可以认为一组，从上往下，依次执行。

	id不同的，id越大,查询的优先级越高。

	

2. type: 查询的类型

1. simple:简单查询 
2.  primary 查询中包含任何复杂的子查询，最外层查询被标记为primary
3. union 第一个select 紧跟union  ,union之后的select被标记为union
4. dependt union  union后select的结果会受 union或unionAll的影响
5. subquery  select或者where条件中包含子查询

   6 dependent subquery  子查询会受到外部select的影响

   7.delivered  from当中派生出来的查询

   8.uncacheable  subquery  子查询的结果不能被缓存





3. table 

	单一数字 实际存在的表名

	deliver 数字 id为几的子查询表

	union(2,3)  union查询 id 为几到几的表

	

4. type 访问类型

	1. All  全表扫描，一行一行的去查找
	2. index 全索引扫描
	3. range  限制了索引的范围
	4. index subquery 利用子查询 关联到了索引
	5. unique subquery 与子查询关联索引类似但使用的是唯一索引
	6. ref   or null  关联条件  为 is  null   or e.id=3333;
	7. ref  使用非唯一性索引进行查找
	8. eq_ref  使用唯一性索引进行查找
	9. const 这个表中匹配至多只有一行





5.possible_keys

查询过程中涉及到字段若存在索引，将被列出，但实际不一定会被使用到

6.key 

实际使用的索引，没有则为null   如果有，则和slect

7.key_len

索引使用的字节长度	，不损失精度的情况下，长度越短越好

8.ref 

索引的哪一列被使用到了

9.rows

查询过程中，实际查找的表数据记录数，越短越好.

10.extra

包含的额外信息





## 2.MYSQL索引

### 1.MYSQL索引使用的数据结构B+树

1. 为什么不使用hash

	如果发生hash碰撞的次数较多，那么hash桶里面的链表可能过长，导致查询数据时，要遍历这个很长的链表，导致查询效率变低.

	如果是等值查询，hash确实能快速查询出对应的数据，但是如果是范围查询，因为hash表的存储是无序的，那么就需要将hash表里所有的数据全部加载到内存，遍历比较。这样大大占用了内存空间.

2. 为什么不使用二叉树

	二叉树虽然有序。但是如果数据的顺序分布不均匀，导致某一边存在非常的链表的话，那么查出是依然要遍历这个很长的链表，影响效率

3. 为什么不是用平衡树，红黑树

	平衡树，红黑树虽然保证了不会出现超长的链表，但是数据的节点依然很深，这样查询数据时，依然要遍历很多树的节点。会造成IO次数的过多，影响读取效率

4. 为社么不使用B树

	B树每个数据块能存储好几个节点的数据，所以一次IO就能读取很多节点的数据，这样大大减少了IO次数。但是由于B树中的数据块也会存储数据，导致存放的节点很少。3次IO能读取16 * 16 * 16的数据。

	但是如果是千万级别的数据，依然要造成较高次数的IO

5. 为什么使用B+树

	B+树与B树的数据结构一样，唯一不同的是B+树的树干不存储实际数据，只有最底层的树叶才会存储数据。树干只存储节点，这样就能存储非常多的节点。3次IO就能读取 160 * 160 *  16的数据 这样也能支持千万级别的数据了。

### 1.索引的分类

1. 主键索引 唯一，非空
2. 唯一索引
3. 普通索引
4. 联合索引
5. 全文索引 适用于varchar char text clob



### 3.索引的优点

1. 大大减少需要扫描的数据量，减少IO次数，与IO流量

2. ？

3. 随机IO变为顺序IO

	随机IO：数据存放在任意磁盘页上。

	顺序IO：数据连续存放在同一个磁盘页上或者临近的磁盘页上

	顺序比随机IO快10倍

	MYSQL使用B+树存储数据索引,存放数据时会将数据存放在连续的4页上16KB

	MYSQL使用索引查询数据时，也会根据索引查询连续的磁页。避免了查询多余的磁页的过程



## 4.专业术语

#### 1.回表

由于MySQL使用B+树,非主键索引的最底层树叶存储是该表的主键值。所以如果查询的是索引列，主键列之外的列的话，那么会根据索引的主键值，再去主键索引中查询对应的实际数据.

```SQL 
SELECT * FROM A WHERE NAME ='1'; -- 会进行回表
SELECT id,NAME FROM A WHERE NAME ='1';--不会进行回表
```



### 2.覆盖索引

只在一颗 索引树上进行查找匹配。

```sql 
SELECT id,NAME FROM A WHERE NAME ='1';--覆盖索引s
```

好处：1.大大减少数据的访问量，提高性能

​            2.因为索引是按照列值顺序存储的，所以对于IO密集型的范围查询会比随机从磁盘读取每一行数据的IO要少的多

​            

### 3.最左匹配

(name,age)联合索引

```SQL 
SELECT * FROM A WHERE NAME ='1' AND AGE=18;--满足最左匹配原则
SELECT * FROM A WHERE  AGE=18 ;--不满足最左匹配原则,不会匹配索引
```

解决方案 

1. 为AGE列单独建立一个索引
2. 修改联合索引为(age,name)



### 4.索引下推

1. MySQL5.6之前  根据联合索引  （name,age) 查询出id，第一次回表，根据name='1' 查出的id进行数据查询，查询出对应name='1' id 的数据,此时MYSQL-server拿到对应的数据，再根据age=18的id,再进行第二次回表 



2. MYSQL5.6之后 根据索引name='1'，age='18'  查找出符合条件的id ,再根据id 回表查询出数据。只用了一次回表

```SQL 
SELECT * FROM A WHERE NAME ='1' AND AGE=18;--回表两次 5.6之前
SELECT * FROM A WHERE NAME ='1' AND AGE=18;--回表一次 5.6之后
```







## 5.索引的匹配方式 

idx_nap` (`name`,`age`,`pos`)

#### 1.全值匹配

```SQL 
explain select * from staffs where name = 'July' and age = '23' and pos = 'dev';
```

#### 2.匹配最左前缀

联合索引会按创建索引顺序，从左到右，依次 获取索引值，如果过滤条件缺少某一列，那么索引只会取已经获取到的列

```SQL  
explain select * from staffs where name = 'July' and age = '23';--匹配了索引 name,age
explain select * from staffs where name = 'July' and pos = '23';--匹配了索引name
```

#### 3匹配列前缀

如果使用模糊查询，那么如果值开头，那么可以匹配到索引。否则匹配不上索引

```SQL 
explain select * from staffs where name like 'J%'; -- 匹配了索引name
explain select * from staffs where name like '%J%'; -- 未匹配索引name
```



#### 4.匹配范围值

索引可以进行范围匹配

```SQL  
explain select * from staffs where name > 'Mary'; 
```



####5.某一索引精确匹配，另一索引范围匹配

```SQL 
explain select * from staffs where name = 'July' and age > 25;
```



#### 6.只访问索引的行

select 索引字段  不需要再进行回表。第二次查询

```sql 
explain select name,age,pos from staffs where name = 'July' and age = 25 and pos = 'dev';
```



## 6.优化小细节

actor_id  主键索引

#### 1.尽量不要将索引列使用表达式计算

```sql 
select actor_id from actor where actor_id=5 --索引
select actor_id from actor where actor_id+1=5  --无索引
```



#### 2.尽量使用主键查询，这样可以有效避免回表



#### 3.使用前缀索引

前缀索引取某一列的前几个字符作为索引

好处：防止索引字段如果过长，有利于构建索引，节省空间

坏处：重复性如果过多，查找起不到索引的作用，降低了索引的选择性

```SQL 
-- 字段 aadsfafasfasadedafsdafafd
-- 前缀索引区该列的前几位 这样就能减少空间
```

解决方案:取这一列的倒数一两位为前缀索引的结束字段，这样既大大发挥了前缀索引的长度，也只在很小程度上降低了索引的选择性

#### 4.排序时尽量使用索引

UNIQUE KEY `rental_date` (`rental_date`,`inventory_id`,`customer_id`)

1. 排序时，联合索引的左列作为精确查询条件 之后排序使用联合索引的右列，那么排序时会使用到联合索引来排序

2. 排序时，联合索引的左列作为范围查询条件 之后排序使用联合索引的右列，那么排序时不会使用联合索引来排序
3. 索引使用升序排列，排序时有一个排序与其他排序不一致，那么也不会使用索引排序
4. 排序列中使用了一个不在联合索引之内的列，那么也不会使用索引排序

```SQL 
explain select rental_id,staff_id from rental where rental_date='2005-05-25' order by inventory_id,customer_id\G;


explain select rental_id,staff_id from rental where rental_date='2005-05-25' order by inventory_id desc\G

explain select rental_id,staff_id from rental where rental_date>'2005-05-25' order by rental_date,inventory_id\G

explain select rental_id,staff_id from rental where rental_date>'2005-05-25' order by inventory_id desc,customer_id asc\G

explain select rental_id,staff_id from rental where rental_date>'2005-05-25' order by inventory_id,staff_id\G

```



####5.union all   in  or  都可以使用索引，但是建议使用 in

1. or会产生多个条件判断
2. in直接范围查找
3. union all实际会一条一条关联



####6.范围列（> ,<）可以用到索引  但不连续范围索引





#### 7.强制类型转换会导致索引失效

数据库是数字类型 =字符类型  mysql自动发生类型转换，导致索引失效



#### 8.频繁更新的列不适宜作为索引，列的重复性过高也不适宜作为索引

一般区分在80%以上就能建立索引 count(distinct(column))/count(\*)统计所占比例





#### 9.建索引的列不应该为null



#### 10.当进行连接查询时，连接的表最好不要超过3张。并且数据类型必须一致



#### 11.能使用limit的尽量使用limit，limit会尽量减少扫描的范围



#### 12.单表索引建议保证在5个左右，索引过多，导致索引文件过大，同样会增大IO量。



#### 13.联合索引的字段不适宜超过5个



#### 14.避免索引越多越好的概念，以及在无了解实际情况的下，盲目优化.



## 7.索引监控

show status like '%Handler_read%';

#### 1.Handler_read_first

读取索引第一个条目次数

#### 2.Handler_read_key

通过索引获取数据数

#### 3.Handler_read_last

读取索引最后一个条目次数

#### 4.Handler_read_next

通过索引读取下一条数据的次数

#### 5.Hanler_read_pre

通过索引读取上一条数据的次数

#### 6.Handler_read_rnd

从固定位置读取数据的次数

#### 7.Handler_read_rnd_next

从数据节点读取下一条数据的次数





## 8.优化查询

#### 1.查询慢的原因

1. 网络

2. IO

3. CPU

4. 高并发，线程上下文的切换

5. 系统调用

6. 生成统计信息

7. 锁的等待

	---------------------》数据量大，筛选数据量耗时长



 #### 2.排查步骤

1. 分析应用程序是否检索了大量不需要的数据

2. 分析MYSQL 服务器是否检索了大量不需要数据

	

	

#### 3.SQL执行过程的优化

1. 查询缓存 MYSQL8.0之后不再使用

2. 语法解析预处理

3. 查询优化器

	3.1 索引的大小，长度

	show status like 'last_query_cost'; 查询消耗时间成本

	3.2 表统计信息

	3.3 有时mysql会选择错误的执行计划

	3.4 
	
	

4. 优化策略

   4.1 优化count查询  myisam count(**) 会维护一个值，因此查询较count(1)较快,别的没有差别

  4.2  优化关联查询

   4.3 优化子查询

   4.4  优化limit分页

  4.5  优化union查询  如果没有特别要求，尽量使用Unionall  







## 9.MySQL用户自定义变量

####1.设置用户自定义变量

set @one:=1

set @one:=(select id from actor where id=1);



####2.自定义变量注意事项

1. 自定义变量无法使用查询缓存

2. :=的优先级非常低，所以只能使用()提高优先级

3. 使用未定义的自定义变量不会产生语法错误

4. 注意取值，赋值的顺序.可能影响我们的预期结果

	

	```SQL 
	set @rownum:=0;
	select actor_id,@rownum:=@rownum+1 as cnt from actor where @rownum<=1;
	-- 因为where和select在查询的不同阶段执行，所以看到查询到两条记录，这不符合预期
	
	
	set @rownum:=0;
	select actor_id,@rownum:=@rownum+1 as cnt from actor where @rownum<=1 order by first_name
	-- 当引入了order by之后，发现打印出了全部结果，这是因为order by引入了文件排序，而where条件是在文件排序操作之前取值的  
	
	-- 解决这个问题的关键在于让变量的赋值和取值发生在执行查询的同一阶段：
	set @rownum:=0;
	select actor_id,@rownum as cnt from actor where (@rownum:=@rownum+1)<=1;
	
	```

	

	





####3.使用案例

1. 优化排名语句,给变量赋值的同时，使用这个变量

	```SQL 
	select actor_id,@rownum:=@rownum+1 as rownum from actor limit 10;
	
	```



2. 按照一定的条件进行排名

```sql 
select actor_id,count(*) as cnt from film_actor group by actor_id order by cnt desc limit 10;
```



3. 避免查询刚刚更新的数据

	```sql 
	update t1 set  lastUpdated=now() where id =1;
	select lastUpdated from t1 where id =1;
	
	-- 用自定义变量 方便效率高
	update t1 set lastupdated = now() where id = 1 and @now:=now();
	select @now;
	```

	







## 10.MySQL分区表

#### 1.为什么使用分区表？

1. 表的数据量非常大,有明确的区分，热点数据，冷数据
2. 分区表的数据更容易维护,批量删除大数据，可以清除整个分区。可以对一个独立的分区进行优化查询
3. 分区表再物理上分为多个数据文件，因此可以存储多个不同的物理设备上，这样高效利用多个物理设备
4. 可以备份恢复独立的分区
5. 可以避免特殊资源的竞争？  （单个索引的互斥访问，文件系统的iNode锁竞争）









#### 2.分区表的类型

1. 范围分区

	```SQL 
	create table ()
	partition by range (分区表达式)
	partition [column] values less  then ([value]),
	partition [column] values less  then ([value]),
	partition [column] values less  then  MAXVALUE
	```

	

2. List分区

	```SQL 
	create table ()
	partition by list (分区表达式)
	partition [column] values in ([value]),
	partition [column] values in ([value])
	```

	

3. 列分区

	允许在分区键使用多列，在分区中放置行，这些列都需要被考虑在内。但是列分区只支持列，不支持表达式。

	

4. hash分区

	简单取模分区键

	```SQL 
	create table()
	partition by hash(分区表达式)
	partitions [num]
	```

	

5. key分区

	不指定，默认使用主键作为分区键

	```SQL 
	CREATE table()
	partition by key()
	partitions [num]
	```

	

6. 子分区

	分区中的分区

	```SQL 
	create table ()
	partition by range (分区表达式)
	subpartition by hash(分区表达式)
	subpartitions [num]
	(partition [name] values less than ([value]),
	partition [name] values less than ([value]),
	partition [name] values less than MAXVALUE
	)
	
	```

	

#### 3.分区表的限制

1. 分区表最多1024个分区 5.7版本8196个分区
2. 如果分区字段中有主键或者唯一索引，那么所有主键列和唯一索引必须包含进来,否则创建报错
3. 分区表无法使用外键约束



#### 4.分区表的底层原理

每个分区表一个单独的数据文件

1. 查询

	查询时，先锁住所有的底层表，优化器过滤出分区，在通过存储引擎接口访问对应分区的数据

2. 插入

	插入时，先锁住所有的底层表，优化器过滤出分区，在通过存储引擎接口插入对应分区的数据

3. 删除

	删除时，先锁住所有的底层表，优化器过滤出分区，在通过存储引擎接口删除对应分区的数据

4. 更新

	 mysql先确定需要更新的记录再哪个分区，然后取出数据并更新，再判断更新后的数据应该再哪个分区，最后 对底层表进行写入操作，并对源数据所在的底层表进行删除操作 

	  虽然每个操作都会“先打开并锁住所有的底层表”，但这并不是说分区表在处理过程中是锁住全表的，如果存储引擎能够自己实现行级锁，例如innodb，则会在分区层释放对应表锁 



#### 5.如何使用分区表?

1. 全表扫描，不需要索引
2. 热点数据包含索引



#### 6.分区表注意事项

1. 插入，更新，打开锁住所有底层表的成本很高
2. null值会使分区过滤无效
3. 分区列和索引列不匹配，导致查询无法进行分区过滤
4. 维护分区的成本很高







##11.MySQL服务器参数设置  my.cnf/my.ini  (linux/windows)

### 1.通用配置

1.  datadir 数据存放位置

2. socket client server在同一台机器，使用localhost连接 就会使用socket连接
3. pid_file  存储 mysql的pid
4. port 端口
5. default_storage_engine 默认存储引擎
6. skip-grant-tables 登录Mql跳过 密码认证，表权限认证



### 2.字符设置

1. character_set_client 客户端数据默认字符集
2. character_set_connection 客户端发送数据，会把这些数据转换为连接的默认字符集
3. character_set_results 发送给客户端结果的数据默认字符集
4. character_set_database 数据库的默认字符集
5. character_set_server  mysql-server的默认字符集



### 3.连接设置

1.  max_connections 最大连接数，数据库的并发连接大，应该调高该值
2. max_user_connections 限制每个用户的最大连接数
3. back_log 当连接数达到max时，多余的连接会被存储在堆栈中，排队处理。如果back_log超出限额了，那么就不在接受连接
4. wait_timeout  关闭非交互连接（短连接）需要等待的时长
5. interactive_timeout 关闭一个交互连接(长连接) 需要等待的时长



### 4.日志设置

####1.错误日志

1. log_error 指定错误日志文件名称，用于记录当mysqld启动和停止时，以及服务器在运行中发生任何严重错误时的相关信息

#### 2.查询日志

1.  一般查询日志 默认关闭

	general_log 

2. 慢查询日志

	slow_query_log 根据设定的时间，记录超过时间的SQL的日志

#### 3.MYSQL bin 日志

log_bin

1. 二进制日志包含了**引起或可能引起数据库改变**(如delete语句但没有匹配行)的事件信息，但绝不会包括select和show这样的查询语句。语句以"事件"的形式保存，所以包含了时间、事件开始和结束位置等信息 

2.  二进制日志是**以事件形式记录的，不是事务日志****(****但可能是基于事务来记录二进制日志)**，不代表它只记录innodb日志，myisam表也一样有二进制日志。 
3.  对于事务表的操作，二进制日志**只在事务提交的时候一次性写入****(****基于事务的innodb****二进制日志)，提交前的每个二进制日志记录都先cache，提交时写入**。 

**注意:只能通过配置文件log-bin=on|filename 开启;**

​          **可以通过mysqlbinlog分析,会记录非查询日志，用于数据库的备份恢复**



#### 4.MYSQL 事务日志（存储的页的二进制数据，属于物理日志。InnoDB执行引擎层面的）

内存----------》logBuffer----------------->OSBuffer-------fsync---->redo/undo的磁盘日志文件

其中可以设置每秒，每次发生变化，将缓存中的数据刷到下一层.

##### 1.redo.log

innodb 会将内存中的增删改数据，异步持久化写到磁盘当中的redo.log去，再到适当的时机，将数据持久化到数据文件

#####2.undo.log

innodb 会将内存中的增删改状态之前的数据，异步持久化写到磁盘当中的undo.log去，一旦发生回滚，立即通过undo.log来恢复数据的原始状态.







### 5.Mysql 缓存的设置

###1.查询缓存（8之后被删除）





### 6.InnoDB设置

#### 1.innodb_buffer_pool_size

该参数指定大小的内存来缓冲数据和索引，最大可以设置为物理内存的80%

#### 2.innodb_flush_log_at_trx_commit

主要控制innodb将log buffer中的数据写入日志文件并flush磁盘的时间点，值分别为0，1，2

#### 3.innodb_thread_concurrency

设置innodb线程的并发数，默认为0表示不受限制，如果要设置建议跟服务器的cpu核心数一致或者是cpu核心数的两倍

#### 4.innodb_log_buffer_size

此参数确定loggerBuffer 缓存区的内存大小，以M为单位

#### 5.innodb_log_file_size

此参数确定数据日志文件的大小，以M为单位

#### 6.innodb_log_files_in_group

以循环方式将日志文件写到多个文件中

#### 7.innodb_file_per_table

每一个表，单独一个数据文件

#### 8.read_rnd_buffer_size

mysql随机读的缓冲区大小

#### 9.read_buffer_size

mysql读入缓冲区大小，对表进行顺序扫描的请求将分配到一个读入缓冲区









## 12.MySql 锁

### 1.事务

####1.特征

1. 原子性：事务是一个整体，要么全部成功，要么全部失败.
2. 一致性：事务提交之前，与事务提交之后。总的数据保持不变.
3. 隔离性：多个事务可以并行。不相互影响.
4. 持久性：事务一旦提交，对数据库的影响是永久的.出故障也能保持。



#### 2.并发事务带来的问题

1. 脏读：一个事务正在修改数据，未提交。另一个事务，读取了修改过后的数据，并且做了业务操作。第一个事务不提交后。业务发生数据不一致.
2. 不可重复读:一个事务正在修改数据，未提交。另一个事务，未读取到第一个事务修改的变动。第一个事务提交后，第二个事务查看，读取第一个事务的变动。第二个事务中，两次数据不一致。
3. 幻读：一个事务正在添加数据,未提交。另一个事务，未读取到第一个事务修改的变动。第一个事务提交后，第二个事务用同样的主键插入。返回插入失败.

注意：事务并发，串行执行，不会产生以上问题。但是执行效率低下。



####3.事务的隔离级别解决 并发带来的问题

1. 读未提交  readUncommitted   脏读  不可重复读  幻读

	```SQL 
	set session transaction isolation level read uncommitted;
	A:start transaction;
	A:select * from psn;
	B:start transaction;
	B:select * from psn;
	A:update psn set name='msb';
	A:selecet * from psn
	B:select * from psn;  --读取的结果msb。产生脏读，因为A事务并没有commit，读取到了不存在的数据
	A:commit;
	B:select * from psn; --读取的数据是msb,因为A事务已经commit，数据永久的被修改
	```

2. 读已提交  read committed  不可重复读  幻读

	```SQL  
	set session transaction isolation level read committed;
	A:start transaction;
	A:select * from psn;
	B:start transaction;
	B:select * from psn;
	--执行到此处的时候发现，两个窗口读取的数据是一致的
	A:update psn set name ='zhangsan' where id = 1;
	A:select * from psn;
	B:select * from psn;
	--执行到此处发现两个窗口读取的数据不一致，B窗口中读取不到更新的数据
	A:commit;
	A:select * from psn;--读取到更新的数据
	B:select * from psn;--也读取到更新的数据
	--发现同一个事务中多次读取数据出现不一致的情况
	```

	

3. 可重复读  read repeatable  幻读

	```SQL 
	set session transaction isolation level repeatable read;
	A:start transaction;
	A:select * from psn;
	B:start transaction;
	B:select * from psn;
	--此时两个窗口读取的数据是一致的
	A:insert into psn values(4,'sisi');
	A:commit;
	A:select * from psn;--读取到添加的数据
	B:select * from psn;--读取不到添加的数据
	B:insert into psn values(4,'sisi');--报错，无法插入数据
	--此时发现读取不到数据，但是在插入的时候不允许插入，出现了幻读，设置更高级别的隔离级别即可解决
	```

4. 可序列化  serializable  

	 在 SERIALIZABLE 隔离级别下，step1 执行时是会隐式的添加 行(X)锁 / gap(X)锁的，从而 step2 会被阻塞，step3 会正常执行，待 T1 提交后，T2 才能继续执行（主键冲突执行失败），对于 T1 来说业务是正确的，成功的阻塞扼杀了扰乱业务的T2，对于T1来说他前期读取的结果是可以支撑其后续业务的。 

### 2.myisam引擎

1. 表共享读锁 读锁

	lock table [tablename]   read ;

	unlock tables;

	占有锁的会话可以读被锁的表，没有占有锁的会话也可以读被锁的表

	占有锁的会话不可以写被锁的表 ， 没有占有锁的会话可以写被锁的表，但会阻塞。直到锁被释放.

	占有锁的会话不可以读，增删改 其他表，没有占有锁的会话可以读，增删改其他表

2. 表独占写锁

	lock table [tablename]  write;

	unlock tables ;

	占有锁的会话可以读，增删改被锁的表。没有占有锁的话，可以读，增删改被锁的表。直到锁被释放。

	占有锁的会话不可以读，增删改 其他表，没有占有锁的会话可以读，增删改其他表

	### 注意:

	**MyISAM在执行查询语句之前，会自动给涉及的所有表加读锁，在执行更新操作前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此用户一般不需要使用命令来显式加锁，上例中的加锁时为了演示效果。**

###3.InnoDb引擎

1. 读锁 又称共享锁

	又称读锁。允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。

2. 写锁 又称排他锁

	又称写锁。允许获取排他锁的事务更新数据，阻止其他事务取得相同的数据集共享读锁和排他写锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。

mysql InnoDB引擎默认的修改数据语句：

1. update,delete,insert都会自动给涉及到的数据加上排他锁，

2. select语句默认不会加任何锁类型**，如果加排他锁可以使用select …for update语句，加共享锁可以使用select … lock in share mode语句。**
3. 所以加过排他锁的数据行在其他事务种是不能修改数据的，也不能通过for update和lock in share mode锁的方式查询数据，但可以直接通过select …from…查询数据，因为普通查询没有任何锁机制。
4. InnoDB行锁是通过给**索引**上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，**否则，InnoDB将使用表锁！**







## 2.Mutipl Version Concurrent Version

并发情况，为了实现快照读与写不冲突，能够并行，不采用加锁的机制，而是采用多版本的控制

### 1.当前读

读的是最新版本，真正的数据。并且读的同时，保证其他事务不能修改数据。 select  for update  ,update 

### 2.快照读

读的时候，可能是最新版本，也可能是历史版本，并且其他事务此时也能并发修改数据。

### 3.数据库隐藏字段，自增id,事务id ,删除标记，回滚指针。

### 4.undo.log

insert undo.log 用户记录数据库的insert  用于回滚.

update  undo.log  用于回滚。 用于MVCC的快照读。

1. 每次事务update 会先添加行锁到真正的数据，等到事务提交之后，才会释放行锁。 

2. 期间会把旧的数据移动到update undo.log当中。 如果成功 什么都不做。如果失败的话，那么回滚。









### 5.readview视图

主要用来做事务读 可见性判断的。决定当前事务应该读哪一个版本的数据。也可能是最新的数据。

当前事务在做快照读的时候，数据库会生成一个READVIEW.



#### readview的属性：

1.list 生成快照读时，系统的正在活跃的事务id 的集合 ，不活跃的id不在此List集合内

2.list中事务id最小的id  minid

3.list中最大的事务id +1  maxid



如果当前行的事务cid 小于  minid，那么说明最近修改当前行的事务 已被提交，那么直接返回 当前行。否则继续判断

如果当前行的事务id 大于等于maxid,那么说明最近修改当前行的事务 发生在本次事务快照读的后面，那么对于本次事务快照读，肯定不可见。 否则继续判断

如果当前行的事务id 大于等于minid 并且小于 maxid的话 那么说明最近修改当前行的事务发生在在本次事务快照读的前面，并且它可能是活跃的事务，也可能是不活跃的。  如果不活跃的说明已经提交，那么对于本次事务快照都是可见的。 如果活跃的说明没有提交，那么对于本次事务快照读是不可见的。  





**<font color='yellow' >readview的可见性算法</font>**

1.取出当前记录的的最新事务id

2.取出系统当前活跃事务的id 由readview 去维护。

如果符合，直接返回结果。

如果不符合，直接根据回滚指针依次查找。比对，直到可见性满足。





### 6.RR级别 RC级别的 ReadView

RR级别 每次事务会使用第一次快照读生成的ReadView。

RC级别 每次事务 每个快照都都会重新生成ReadView.







































## 13.Mysql主从同步集群

1. 可以通过中间件来访问一个集群 mycat
2. 主从同步主要通过binlog方式同步数据。5.7版本可以并行复制数据。实现零延迟的同步数据。















===========================================MYSQL设置新密码=======================================================================
1，mysqld --console --skip-grant-tables --shared-memory //开启无密码登录MYSQL服务模式,
2，update user set authentication_string='' where user='root';
3，ALTER USER 'root'@'localhost' IDENTIFIED BY '新密码'; //5.7.5以后
4，set password for root@localhost=password('');//5.7.5以前
============================================MYSQL navicate not support authorication======================================================================
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'newpassword';



============================================MYSQL不同引擎数据库文件存储======================================================================
了解MYSQL的都知道，在MYSQL中建立任何一张数据表，在其数据目录对应的数据库目录下都有对应表的.frm文件,.frm文件是用来保存每个数据表的元数据(meta)信息，包括表结构的定义等，.frm文件跟数据库存储引擎无关，也就是任何存储引擎的数据表都必须有.frm文件，命名方式为数据表名.frm，如user.frm. .frm文件可以用来在数据库崩溃时恢复表结构。

MySQL文件包括MySQL所建数据库文件和MySQL所用引擎创建的数据库文件。

.frm 文件与操作系统和数据库引擎无关，都有这么个与表名同名文件。

MyISAM引擎的文件：

.myd 即 my data，表数据文件

.myi 即my index，索引文件

.log 日志文件。

InnoDB引擎的文件：

采用表空间（tablespace）来管理数据，存储表数据和索引，

InnoDB数据库文件（即InnoDB文件集，ib-file set）：

ibdata1、ibdata2等：系统表空间文件，存储InnoDB系统信息和用户数据库表数据和索引，所有表共用。

.ibd文件：单表表空间文件，每个表使用一个表空间文件（file per table），存放用户数据库表数据和索引。

日志文件： ib_logfile1、ib_logfile2

################################################################################################################################################################

Innodb存储引擎管理主要基于两个文件：表空间数据文件和日志文件。

InnoDB存储它的表＆索引在一个表空间中，表空间可以包含数个文件（或原始磁盘分区）。

如果没有指定InnoDB配置选项，MySQL将在MySQL数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile 1的5MB大小的日志文件。

ibdata1的大小在my.cnf文件中配置：innodb_data_file_path = ibdata1:10G:autoextend

可以设置最大数据文件限制，以免超过系统支持的最大文件：

innodb_data_file_path = ibdata1:100M:autoextend:max:500M

日志文件大小在my.cnf文件中配置：innodb_log_file_size  = 256M  innodb_log_files_in_group = 2

Innodb存储引擎可以使用共享表空间或独立表空间，使用独立表空间时，需要将innodb_file_per_table加到配置文件中，也可以在variables中开启。

共享表空间是将所有的表的数据和索引保存在ibdata1中，这样的缺点是拷贝时必须拷贝整个大文件，而且删除表后容易产生碎片。

独立表空间是为每个表建立一个.ibd文件用来存储数据和.frm用来存数据词典信息，这样，mysql就将innodb表的数据存入各自对应的.ibd文件中了，但结构等信息还是会写入ibdata。

innodb_file_per_table变量只能在配置文件里修改，不能使用set global ...

将innodb_file_per_table关闭之后，建立innoDB表时只生成.frm文件，数据和索引都保存在共享表空间ibdata1中。################################################################################################################################################################

MySQL数据库存放位置：

1、MySQL如果使用MyISAM存储引擎，数据库文件类型就包括.frm、.MYD、.MYI，默认存放位置是C:\Documentsand Settings\All Users\Application Data\MySQL\MySQL Server 5.1\data

2、MySQL如果使用InnoDB存储引擎，数据库文件类型就包括.frm、ibdata1、.ibd，存放位置有两个，

.frm文件默认存放位置是C:\Documents and Settings\All Users\ApplicationData\MySQL\MySQL Server 5.1\data，ibdata1、.ibd文件默认存放位置是MySQL安装目录下的data文件夹
========================================================MYSQL导出数据文件命令==========================================================

1. 用 SELECT…INTO OUTFILE 导出文本文件
 在 MySQL 数据库中导出数据时，允许使用包含导出定义的 SELECT 语句进行数据的导出操作。
    该文件在服务器主机上创建，因此必须拥有文件写入权限 (FILE权限)，
    才能使用此语法。“SELECT...INTO OUTFILE 'filename' " 形式的 SELECT语句可以把被选择的行写入一个文件中，filename 不能是一个已经存在的文件。
    SELECT...INTO OUTFILE 语句的基本格式如下:

SELECT columnlist FROM table WHERE condition  INTO OUTFILE 'filename' [OPTION]

--OPTIONS 选项
　　FIELDS TERMINATED BY 'value'
　　FIELDS [OPTIONALLY]  ENCLOSED BY 'value' 
　　FIELDS ESCAPED BY 'value' 
　　LINES STARTING BY 'value'  
　　LINES TERMINATED BY 'value'  
SELECT columnlist FROM table WHERE condition 为查询语句，查询结果返回满足指定条件的一条或多条记录；
INTO OUTFLE 语句的作用就是把 SELECT 语句查询出来的结果导出到名称为 filename 的外部文件中，
[OPTIONS] 为可选参数选项，OPTIONS 部分的语法包括 FIELDS 和 LINES 子句。

  FIELDS TERMINATED BY  'value' 设置字段之间的分隔符可以为单个或多个字符，默认情况下为制表符“\t”。
 FIELDS [OPTIONALLY] ENCLOSED BY 'value' 设置字段的包围字符，只能为单个字符，如果使用了OPTIONALLY 
 则只包括 CHAR 和 VARCHAR 等字符数据字段。
FIELDS ESCAPED BY 'value' 设置如何写入或读取特殊字符，只能为单个字符，即设置转义字符，默认值为“\”。
LINES STARTING BY 'value'  设置每行数据开头的字符，可以为单个或多个字符，默认情况下不使用任何字符。
LINES TERMINATED BY 'value' 设置每行数据结尾的字符，可以为单个或多个字符，默认值为“\n”。
FIELDS 和 LINES 两个子句都是自选的，但是如果两个都被指定了，FIELDS 必须位于 LINES 的前面。

SELECT...INTO OUTFILE 语句可以非常快速地把一个表转储到服务器上。如果想要在服务器主机之外的部分客户主机上创建结果文件，
不能使用 SELECT...INTO OUTFILE 语句。在这种情况下，应该在客户主机上使用 mysql -e “SELECT ... " > file_name 这样的命令，来生成文件。

看看到默认情况下，MySQL 使用制表符“\t”分隔不同的字段，字段没有用其他字符括起来。Windows系统下的回车换行为“\r\n”，默认换行符为“\n”。
默认情况下，如果遇到 NULL 值，将会返回“\N”代表空值，反斜线“\”表示转义字符。如果使用 ESCAPED BY 选项，则N前面为指定的转义字符。

2. 用 mysqldump 命令导出文本文件
使用 mysqldump 工具不仅可以将数据导出为包含 CREATE、INSERT 的 sql 文件，也可以导出为纯文本文件。

Mysqldump 将创建一个包含 CREATE TABLE 语句的 tablename.sql 文件和一个包含其数据的 tablename.txt 文件。

mysqldump 导出文本文件的基本语法格式如下:

mysqldump -T path -u root -p dbname [tables] [OPTIONS]

--OPTION 选项
--fields-terminated-by=value
--fields-enclosed-by=value
--fields-optionally-enclosed-by=value
--fields-escaped-by=value
--lines-terminated-by=value

  只有指定了 -T 参数才可以导出纯文本文件；path 表示导出数据的目录；tables 为指定要导出的表名，如果不指定，将导出数据库 dbname 中所有的表； [ OPTIONS] 为可选参数选项，这些选项需要结合-T 选项使用。

OPTIONS 常见的取值如下:

  --fields-terminated-by=value:设置字段之间的分隔符可以为单个或多个字符，默认情况下为制表符“\t”。
 --fields-enclosed-by=value: 设置字段的包围字符。
 --fields-optionally-enclosed-by=value： 设置字段的包围字符，只能为单个字符，包括 CHAR 和 VARCHAR 等字符数据字段。
  --fields-escaped-by=value： 控制如何写入或读取特殊字符，只能为单个字符，即设置转义字符，默认值为“\”。
 --lines-terminated-by=value：设置每行数据结尾的字符，可以为单个或多个字符，默认值为“\n”。


3. 用 mysql 命令导出文本文件
  相比mysqldump，mysql工具导出的结果可读性更强。

使用 mysql 导出数据文本文件语句的基本格式：

mysql -u root -p --execute= "SELECT 语句" dbname >filename.txt

-execute 选项表示执行该选项后面的语句并退出，后面的语句必须用双引号括起来，dbname 为要导出的数据库名称；
导出的文件中不同列之间使用制表符分隔，第1行包含各字段的名称。
使用 --vertical  参数显示结果。




====================================================MYSQL导入数据文件命令==============================================================

mysql 5.5.7以上不行 必须修改全局变量local_infile=1  还要以mysql --local-file=1 启动

 1.用 LOAD DATA INFILE 导入文本文件
  语法格式如下：

LOAD DATA  INFILE  'filename.txt'  INTO  TABLE   tablename  [OPTIONS]  [IGNORE number LINES]

--OPTIONS 选项
　　FIELDS  TERMINATED  BY  'value'   /*设置字段之间分隔符，单个或多个字符，默认为'\t'*/
　　FIELDS  [OPTIONALLY]  ENCLOSEED BY  'value'  /*设置字段包围分隔符，单个字符*/
　　FIELDS  ESCAPED  BY  'value'     /*如何写入或读取特殊字符，单个字符*/
　　LINES  STARTING BY  'value'     /*每行数据开头的字符，单个或多个*/
　　LINES  TERMINATED  BY  'value'   /*每行数据结尾的字符，单个或多个*/

2.用 mysqlimport 命令导入文本文件
 使用 mysqlimport 可以导入文本文件，并且不需要登录 MySQL 客户端。mysqlimport 命令提供了许多与LOAD DATA INFILE 语句相同的功能。
 使用 mysqlimport 语句需要指定所需的选项、导入的数据库名称以及导入的数据文件的路径和名称。

语法格式如下：

 mysqlimport -u root -p dbname filename.txt [OPTIONS]

 --fields-terminated-by=字符串：设置字符串为字段之间的分隔符，可以为单个或多个字符。默认值为制表符“\t”。
-L, --local：表示从客户端任意路径读取文件导入表中，未设置该选项时，默认只从datadir下同名数据库目录下读取文件导入
--ignore-lines=n：表示可以忽略前n行。
-l, --lock-tables：写入时锁定所有表
-p, --password[=name]：指定用户密码
-u, --user=name：指定登入MySQL用户名
-h, --host=name：指定远程连接的服务器
-c, --columns=name：往表里导入指定字段，如：--columns='Name,Age,Gender'
-C, --compress：在客户端和服务器之间启用压缩传递所有信息

 --OPTION 选项
 --fields-terminated-by=value
 --fields-enclosed-by=value
 --fields-optionally-enclosed-by=value
 --fields-escaped-by=value
 --lines-terminated-by=value
 --ignore-lines=n



  dbname 为导入的表所在的数据库名称。mysqlimport 命令不指定导入数据库的表名称，数据表的名称由导入文件的名称确定，即文件名作为表名，导入数据之前该表必须存在。


OPTIONS 为可选参数选项，其常见的取值如下：

 --fields-terminated-by=value:设置字段之间的分隔符，可以为单个或多个字符，默认情况下为制表符“\t”。
 --fields-enclosed-by=value: 设置字段的包围字符。
 --fields-optionally-enclosed-by=value： 设置字段的包围字符，只能为单个字符，只包括 CHAR 和 VARCHAR 等字符数据字段。
  --fields-escaped-by=value： 控制如何写入或读取特殊字符，只能为单个字符，即设置转义字符，默认值为“\”。
 --lines-terminated-by=value：设置每行数据结尾的字符，可以为单个或多个字符，默认值为“\n”。
--ignore-lines=n： 忽视数据文件的前 n 行

【注】双引号要用转义字符
mysql转义字符
\0
一个ASCII 0 (NUL)字符。
\n
一个新行符。
\t
一个定位符。
\r
一个回车符。
\b
一个退格符。
\ '
一个单引号(“ '”)符。
\ "
一个双引号(“ "”)符。
\\
一个反斜线(“\”)符。
\%
一个“%”符。它用于在正文中搜索“%”的文字实例，否则这里“%”将解释为一个通配符。
\_
一个“_”符。它用于在正文中搜索“_”的文字实例，否则这里“_”将解释为一个通配符。
注意，如果你在某些正文环境中使用“\%”或“\%_”，这些将返回字符串“\%”和“\_”而不是“%”和“_”。

有几种方法在一个字符串内包括引号：

一个字符串内用“ '”加引号的“ '”可以被写作为“ ' '”。
一个字符串内用“ "”加引号的“ "”可以被写作为“ " "”。
你可以把一个转义字符（“\”）放在引号前面。
一个字符串内用“ "”加引号的“ '”不需要特殊对待而且不必被重复或转义。同理，一个字符串内用“ '”加引号的与“ "”也不需要特殊对待。





==================================================================================================================

====================================================MYSQL常用函数==============================================================
current_timestamp() 当前时间戳



route  add 10.0.0.0 mask 255.0.0.0   10.242.103.120