

## 1.REDIS的源码包安装

1. wget,或者通过别的方式获取redis的源码压缩包

2. 解压，阅读README.MD  INSTALL部分

3. Makefile文件的目录下  make 命令编译(需要gcc依赖)

4. make install 安装编译好的程序  PREFIX=[目标目录]  安装到指定目录

5. 根据utils 下的Install-server.sh (官方推荐) 启动相应的redis 实例  比如指定端口,配置文件,启动日志....

	port

	conf 配置文件

	log文件

	datadir 数据存放位置

	executable  redis-server的可执行程序
	
	

## 2.REDIS String 数据类型 命令详解(help @string->help [具体命令] 得到相应命令操作提示)

1.get

2.set XX/NX

3.strlen(统计字节数):**Redis是二进制安全型的存储，按照一个字节，每个字符都是按照一个字节存储的,客户端显示的字符实际上都是按照其相应的字符编码转成的字节如（ASCII/GBK/UTF-8）**

**A----->0100 0001 **

**@--------->0100 0000**



4.setbit  key [index]  [0/1]

在指定bit位设置 0或者1 



5.bitcount key [startindex]  [endindex]

统计bit位置为1的数量



6.object encoding  key 看此key Value对应的实际数据类型



7.bitop  or newkey  key1  key2  对key相应的value做或位运算



8.bitop and newkey key1 key2 对key相应的value做与位运算



7.案例

1. 统计每个用户一年的实际登陆天数

	1. 每个用户设定一个key   假设1000，0000用户

	2. 此key对应设置value,value的 每个bit位代表当前用户是否登陆了 360/8  每个值的大小45bytes, setbit key [0-359] [1]

	3. bcount key [0]  [-1] 统计一年任意范围用户的登陆总天数

	4. 45\*1000,0000 bytes=45*\*1000,0 kbytes=45**10 mbytes*=450MB

		

2. 统计一年所有的活跃用户数量

	1. 为每一天设定一个key   

	2. 此key对应设置value,每个bit位代表每个用户是否登陆了

	3.  1000 0000 0000 0000--------》1100 0000 0000 0000（一号用户登陆了，二号用户登陆了）

	4. 如果还有用户登陆操作，则在该天的key-value上进行位的or运算，如果是第一个用户就在第0个bit位上,如果是第二个用户就在第1个bit位上,  每一天的key-value进行or运算 存贮到一个新的 key上

		bitop newkey key1 key2 ,newkey中就是统计出了所有天数登陆的用户数.

	5. 最终在bcount newkey [0]  [-1] 即可统计活跃用户数量





## 3.REDIS List 数据类型 命令详解(help @list->help [具体命令] 得到相应命令操作提示)

1. lpush/rpush  key  element1 element2 压栈  反向 /同向  栈结构/队列结构
3. lrange key  0 -1  按索引 遍历list   数组
4. lpop/rpop  key  向左弹出，向右弹出 元素
6. blpop key  time 阻塞时的弹出集合中的元素，如果time为0，那么会一直阻塞，直至有结果返回。  阻塞队列
7. ltrim  start  end  取出两端之外的元素





## 4.REDIS hash数据类型 命令详解



1. hset hashkeys  key value 这是hash类型

2. hincrby hashkeys key 增加量   
3. 应用场景：点赞，收藏。给对应对象的属性赋值



## 5. RESIS set  数据类型(无序，去重)

1. SRANDMEMBER  key  count   随机事件   

	count=0不返回 

	count>0 随机返回去重结果 但不大于总元素数

	count<0 随机返回可以有重复的结果 可以大于总元素数



## 6. Redis sortedset(zset) 数据类型:多了一个分值(score)，分值用于集合元素之间的排序,zset 物理空间上是从左到右存储元素的

1. zrange/zrevrange   从左到右/从右到左 获取set 的值

2. zunionstore  newkey  numkey  key1 key2 ...   weights 1 2  aggregate   sum/max 求出并集存入新集合

3. zset 之所以查询快 是应为底层使用了跳表结构

	 跳表 数据存在于最底层链表   中间存在几层链表，但是中间的链表元素不全。并且相同元素上下是有指向的。大大降低了查询的范围



## 7. Redis  发布，订阅消息 help @pubsub

1.publish channel  messages  向一个通道发布消息

2.subscribe channel  订阅一个通道的消息。只能获取订阅之后 通道发布的消息。订阅之前的不会显示

3.问题：一个聊天群，如何处理实时消息，三天内的信息。三天之外的信息.

1. 实时消息可以利用redis的pubsub功能实现。过个客户端发布，订阅群的channel,只要发布消息，那么订阅的客户端就能实时接收到发布的消息
2. 三天之内的消息 可以存储在Redis的sortedSet当中。取消息产生的时间为sortedset的分值.这样每条消息就按时间顺讯排列，存储在redis当中。
3. 再次可以设计一个redis专门负责实时消息的发布，展示。另外一个redis订阅此通道的消息专门用户处理三天之内消息的存储。
4. 三天之外的消息，有redis的sortedset移交给数据库。并且三天之外消息的存储都查询数据库.



## 8.Redis 的缓存穿透

1. 有时经常会有查询Redis中不存在的数据，数据库也不存在的数据。这种数据会将大量的请求压力，转向数据库。

2. 对于这种请求，可以引入Redis的bloom过滤器，

3. Bloom过滤器的原理:

	1. 底层维护一个bitmap数组，每一个都是二进制位。

	2. 有一个新值元素插入进来，生成一定数量的HahsFunction(). 如果计算出来的HashFunction的值，命中bitmap的索引，那么就在此索引的值变为1.

	3. 当查询一个元素，也生成一定数量的HashFunction(),如果生成的值有一个为0，就判定，此元素不存在。如果都为0，则判定此元素存在。进行查询

	4. 此算法会有一定的错误率，即使元素的hashFunction()的值的位置都为1，那么也存在此元素实际不存在的情况。对于这种，可以在查询数据库发现数据并未存在过后，及时更新缓存。标记此元素不存在.

	5. 数据库的元素增加了，及时更新缓存

		



4. bloom过滤器的使用
	1. bf.add  过滤器名称   值   指定过滤器添加，不存在则新建
	2. bf.exists 过滤器名称  值  查看过滤器是否存在某值





## 9.Redis的过期键淘汰策略

1. 过期键的回收原理有两种方式

	被动回收：客户端请求键，服务端，发现已经达到过期时间。回收此键

	主动回收：默认每秒检测10次，检测对象是所有设置了过期键时间的集合。抽样取出20个过期键，看是否存在过期键，如果存在就删除。再检测过期键占总集合的比例，看是否超过了25%，如果是，再次重复上一步。直至已经过期的键占设置了过期键集合的比例小于25%。



## 10.如何解决缓存达到设置的最大限制 maxmemory 采用回收策略(LRU:最长时间没有使用，LFU：最少使用次数)

1. maxmemory 一般可以手动指定，当插入键时，超过了maxmeomory设置的值，就会触发内存回收策略
2. 回收策略
	1. noeviction 服务端返回错误，不会驱除任何键
	2. allkeys-LRU  回收所有最长时间没有使用的键
	3. volatile-LRU 从设置了过期时间的键集合中回收最长时间没有使用的键
	4. allkeys-random 从所有keys随机删除
	5. volatile-random 从设置了过期时间的键集合中随机回收最长时间没有使用的键
	6. volatile-ttl 从设置了过期时间的键集合中回收所有过期了的键
	7. volatile-lfu 从设置了过期时间的键集合回收最少使用次数的键
	8. allkeys-lfu 从所有keys回收最少使用次数的键

2. LRU（最长时间未被使用的键）算法：

	1. Redis内部维护一个24位的全局时钟（单位秒）。每个key内部维护一个24位的时钟。全局时钟能存贮的最大值194天。达到最大后归为0.
	2. 当key发生修改，访问时，key内部的时钟更新为全局系统的时间。
	3. 如果 采用LRU算法的话，那么会将key内部的时钟和全局时钟做比较。当key内部的时钟小于全局时钟，计算两者差值。当key内部的时钟大于全局时钟，计算两者和。差值最大的即为最长时间未被使用的键。进行淘汰。Reids会进行抽样，删除抽样中符合LRU算法的键。

3. LFU（最少使用次数的键）算法：

	1. LRU的问题:经常使用的key可能被LRU算法删除

		A--->A--->A-->A-->A-->A-->A-->A------>A

		B--------->B--------->B----------->B---------->B-->B

	2. LFU内部key把前16位当中时钟,单位时分秒.（每次访问时更新16位）,后8位当做访问次数.如果一个key没被访问，那么会随着时间的增长，访问次数减小。访问间隔越长，访问的次数就越小。（访问次数最大数值255）

	3. lfu-delay-time 为衰退因子。单位为分钟。当为1时，表示表示每一分钟没被访问，次数减1.

	4. 具体是当前时间转化成分钟数后取低16 bits，然后计算与`ldt`的差值`now-ldt`。当`ldt > now`时，默认为过了一个周期(16 bits，最大65535)，取值`65535-ldt+now`。然后用差值与配置`lfu_decay_time`相除，`LFUTimeElapsed(ldt) / server.lfu_decay_time`，已过去n个`lfu_decay_time`，则将`counter`减少n，`counter - num_periods`。

	5. 新生key策略：新生的key次数默认为5，防止过快被淘汰.

​          



## 11.linux的父子进程概念

1.  linux 父进程可以fork出一个子进程
2. fork：  一个进程调用fork（）函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后把原来的进程的所有值都复制到新的新进程中，只有少数值与原来的进程的值不同。相当于克隆了一个自己。 
3. 父子进程需要通信。export 可以让子进程看到父进程的数据
4. 子进程对父进程变量的修改不会影响到父进程。父进程对子进程的修改也不会影响到子进程。
5. 如果完全复制两份不同的变量那么会大大占用内存空间，以及执行效率.所以为了实现父子进程互补影响，以及提高效率，优化内存。使用了copywrite 写时复制技术
6. 父子进程共享内存，当有一方发生变动时，则copy出一份新的内存给改变的一方引用。这样节省了空间，时间.



## 12.数据库的快照机制和日志机制

1. 所有数据库都有快照，快照就是一个数据库某一个时间节点上的所有数据的一个拷贝，所以可以通过快照恢复某一时间节点的数据。
2. 所有数据库的增删改操作命令，都会先写入日志，在进行实际数据库操作。所以可以通过日志来追溯用户的操作记录

## 13.Redis既可当做缓存，也可以当做数据库。缓存是用来存放热数据的，一些经常使用的数据，或者最新的数据。数据库用来存放冷数据的。一些不经常使用的数据。



## 14.Redis的快照机制实现（RDB）

1.  利用了linux的fork函数，通过fork开启子线程，利用子线程来形成快照。因为fork底层采用的写时复制，因此，在产生快照的同时，对redis的增删改,不会影响redis快照文件的准确性与时效性.

2.  RDB  备份的数据在datadir里面的 dump.rdb

	手动触发RDB：save 同步阻塞，完成快照才能进行访问，bgsave 后台fork 写时复制 不影响使用

	自动触发 配置文件 save seconds  changes 多少秒以内 发生变化 进行RDB



   3.优点：恢复速度快，因为直接就是二进制文件

4. 缺点：1,会丢失一部分数据（在bgsave之后，新增或者修改的数据）

	​            2,永远只是一个文件，每次要备份，不支持拉链

	

## 15.Redis日志机制的实现(AOF)

### 4.0之前

1. rdb和AOF可以同时开启，但是开启了AOF之后，只会用AOF恢复数据,AOF包含了RDB二进制数据的全量命令。

2. 此处AOF文件的解析会有一个过程，该过程会读取AOF全量命令，删除重复命令，在执行
3. 优点：只会丢掉很少一部分数据。几乎可以忽略不计。

4.  缺点：需要解析过程，效率低。文件可能很大。

	

### 4.0之后

  使用bgrewriteaof 会重新生成AOF文件，此文件包含RDB文件信息+命令信息 以 REDIS开头。

1. rdb和AOF可以同时开启，但是开启了AOF之后，只会用AOF恢复数据,AOF包含了RDB的数据文件。会先通过AOF的RDB文件恢复数据库，再读取AOF增量命令日志恢复数据

2. 当单个AOF文件越来越大时， 可以配置自动进行AOF文件的重写

	auto-aof-rewrite-percentage 100 自动重写aof文件增长的比例，当超过这个比例开启重写
	auto-aof-rewrite-min-size 64mb  自动重写aof文件的最小大小



#### AOF重写发生IO 对缓冲去 刷新的设置

appendfsync always  一旦发生IO 同步就刷新Buffer ,几乎不会发生漏数据，只要进入Buffer就刷入磁盘

appendfsync everysec 每秒异步刷新Buffer  丢失少量的数据  1秒还未到达 服务宕机，此过程的数据未刷入磁盘

appendfsync no 不进行主动刷新Buffer,当Buffer满了才出发刷新， 会流失Buffer未满时的数据。







## 16.Redis 解决单节点问题的方法

#### 1.单节点的问题

1. 单节点故障
2. 压力大
3. 容量上限



#### 2.AKF原则

1. X轴   对单节点进行全量备份，形成一个镜像。 主进行读写，从只进行读, 这样解决了单节点故障，缓解了压力，但是仍然解决不了容量的问题.

2. Y轴  对数据进行功能划分，根据具体业务不同，划分成不同的模块，同一模块进行X轴拓展,这样解决了单节点故障，缓解了压力，也解决了容量的问题.
3. Z轴  进行数据的区域划分，每个区域自称一个整体。是一个单元，往Z轴拓展，就形成了多个单元。每个单元相互独立。 
	1. 数据区域分区 ：分库分表
	2. 应用区域划分： 每个城市的系统自称单元.



#### 3.CAP理论

#####1.数据的强一致性

一台服务器接收读写请求，同步阻塞式的给另外两台服务器同步数据。如果同步失败，返回客户端失败.

虽然保持了数据的强一致性，但是客户端体验较差。可用性极差



##### 2.高可用性

一台服务器接收读写请求，异步给另外两台服务器同步数据。即使同步失败，依然给客户端提供正常服务。

虽然维持了服务的可用性。但是缺少了一致性.

##### 3.中间取差值

一台服务器接收读写请求，异步给中间件，中间件（kafka等，具有高效传输数据的能力）给另外两台服务器同步数据。

这样虽然有可能导致数据的不一致性，但是最终会导致数据的一致性。

弱一致性和高可用性.



#####4.分区容错性

三台节点。如果其中有一台宕机了。到底服务可用不可用？

1.如果不可用，强一致性。 

2.如果可用，可以允许一台宕机。只要其他两台可用就行。满足分区容错性.



有多少节点可用，才判定服务可用性？半数以上原则

1.如果是2台，产生脑裂，无法判定是否可用。

2.如果是3台，2台可用，整体就可用。

3.如果是4台，3台可用，整体就可用。

4.如果是n台，就是n/2+1台有用

一般使用奇数台，偶数台造成的不可用风险概率比奇数台要高。即 不可用服务宕机的数量大于偶数



##### 5.Redis主从机制

1. 主从复制

	一台主节点。读写数据。从节点分担读压力（可以配置成读写）。从节点异步向主节点同步数据

从节点配置指定主节点

​    每次同步数据的时候，当前节点会剔除自己的老数据，再同步主节点的数据.

2. 开启AOF会进行全量同步，缺少replication-id



2. 如果主节点发生了故障，如果处理？

1. 人为处理

	选择其中一个从节点 replicaof no one 断掉同步

	其余节点replicaof  此节点

1. replica-serve-stale-data yes 从节点同步数据时，是否支持查询

2. repl-diskless-sync no 同步是否走磁盘

	repl-backlog-size 1mb  增量复制  存贮同步数据 的进度日志。队列有大小，超出容量 全量复制

	\#增量复制

	min-replicas-to-write 3
	min-replicas-max-lag 10





##17.Redis哨兵模式  把主从复制的监控，以及故障处理交给哨兵程序处理

#### 1.哨兵模式的启动

1.Redis-server的内部功能）直接将redis-server 启动模式改为哨兵，则该redis实例停止正常的功能启动哨兵功能  redis-server  --sentinel哨兵配置文件

2.直接运行redis-sentinel 程序。额外开启哨兵  redis-sentinel   哨兵配置文件

3.哨兵会自动监视主从的信息，如果master宕机，那么会自动重新选出一台从作为master

4.如果过半哨兵都认为某台redis服务器宕机，那么此redis就被认定为不可用状态     









## 18.Redis主从模式解决不了容量上限的问题

#### 1. 主从模式解决不了容量上限的问题，为了解决容量问题，可以把数据进行归类

#### 2.当用户想要访问数据时，需要从对应的分类中取出数据。有以下方法可以解决从正确的分类中取出数据

##### 1.hash+取模  %3，%4.。。。。

1. 优点:每次建立数据可以根据数据算出hash值，放入对应的节点中。查询时，也可以根据hash值，取到对应节点的数据
2. 缺点: 如果增加节点，需要重新计算hash值，成本大





##### 2.random 随机放入一台节点

1. 优点:增加节点，解决了容量上限问题

2. 缺点：查询数据时，无法知道数据存放在哪台节点。可能要遍历所有节点，才能取到正确的数据.

3. 适合特定业务场景：假如都是list类型数据,每次查询 rpop,功能有点像消息队列。kafka典型代表。

	topic  topic再分replica



#####3.一致性hash 算法

把节点的相关信息进行hash运算。逻辑上生成一种hash环。物理节点的相关信息散落在hash环上，当有数据生成时把数据的key也进行hash运算。得出的值距离那个物理节点的hash最近，就存放在哪台节点上.



1. 优点：增加了节点，解决了容量上限问题

	​           当新增节点时，也不用进行rehash计算。节省了成本。不会造成全局洗牌.

2. 缺点: 新hash节点机器的一边数据会查询不到，导致缓存穿透。（可以取两个最近的物理节点）

	​          另一边的节点机器可能出现数据倾斜问题，（进行Redis  LFU,LRU缓存淘汰机制）

	此种方案更偏向于redis当做缓存使用。

	​          



### 19.当对客户端的连接很多时，会影响server的工作效率。有以下解决方案

#### 1.在客户端服务端中间做一层代理 modula  random   kemata（可以有多台代理负载均衡）

这种代理不处理其他任何工作，只进行接收发送请求。称作无状态的。



#### 2.如果代理依然不能满足大量并发请求的状况，在代理之前，可以做一层LVS LVS 只管发送请求，不管响应。对此台LVS 可以做主备机制。备用一台LVS以防万一。





### 20.数据分治，很难实现数据的聚合操作。比如一个请求中要实现多种数据的查找。

#### 1.预分区（直接取一个较大的模比如10。这样hash桶较多）做法：可以在每个服务节点内部维护一个hash值的映射关系。如果映射到本台服务，则取出数据。如果没有映射到本台，则去查找内部hash值映射。找到对应的服务节点。依次类推，找到用户需要的所有数据。返回。如果新增一个节点。旧节点转移一部分hash映射给新节点。并将对应映射的数据同步到新节点上。





#### 2.Redis集群Cluster帮我们解决了这个问题，redis集群总共可以有16384个hash桶。存数据的时候可以跟数据的hash值，存放在不同的hash桶内。如果需要用到各个分区的数据的话，redis会根据数据查找本服务hash桶内的数据，没有的也会直接集群内的其他redis查找，只有全部返回客户端。如果新增一个节点。旧节点转移一部分hash映射给新节点。并将对应映射的数据同步到新节点上。删除节点只需删除hash桶就行。







### 21.Redis集群的基本搭建

#### 1.修改配置文件，启动redis集群模式

```properties
port 7000
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 5000
appendonly yes
```



#### 2.redis-cli  --cluster create [ip:port]  [ip:port]  [ip:port]   [ip:port] ..... --cluster-replicas [n]  创建集群

指定从节点数量.

#### 3.创建集群成功，此时客户端开启集群模式访问 redis-cli -c  插入数据就会根据数据的hash值插入对应的hash槽。

#####1.hash槽的重新分片 resharding

redis-cli  -p []  --cluster reshard 分片    结束 node:done

##### 2.新增节点

redis-cli  --cluster  新节点  集群节点  （主节点）

redis-cli  --cluster  主节点  主节点   --cluster-slave --cluster-master-id 







## 22.Redis中击穿，穿透，雪崩问题

### 1.击穿

数据库中有的数据，redis中由于key过期或者LFU,LRU内存不足的淘汰机制，导致key数据不存在。并发量大的时候，这些查询压力都转移至数据库了。

解决方案:

setNX 设置分布式锁，当key不存在时，不让所有请求都去数据库，一次只允许一个请求实例请求数据库，其他请求阻塞睡眠等待。请求数据库成功之后更新Redis释放锁。其他请求再从Redis获取数据。

请求1 getKey  请求2 getKey 如果没有 setNx

请求1 获得setNX锁，请求数据库，更新Redis  请求2 未获得setNX锁  睡眠等待



setNX锁产生的问题：

请求1占用锁后，请求数据库挂了，一直占用锁？导致其他请求一直等待锁的释放。--------》设置锁的过期时间



设置锁的过期时间产生的问题：

请求1占用锁后，请求数据库没挂，锁过期了。请求1依然对数据库保持请求。  锁过期后，其他线程也获得了锁纷纷去请求数据库。大量压力有转移至数据库了。-----------------》》开启两个线程，一个线程去查询数据库，另外一个线程，去监视查询数据库的线程，看是否查询成功。如果在锁的过期时间之内没有setNx成功，更新锁的过期时间。



###2.穿透

数据库中不存在的数据，redis中自然也没有。这些查询压力透过redis转移至数据库

解决方案:

1.客户端请求使用映射函数，redis自身维护一个bitMap,存贮一个数据，将数据映射至bitmap的1.查询一个数据，查询这个数据是否与bitMap一致。

2.客户端不做任何操作，redis引入布隆模块，自身维护bitMap并且用映射函数进行映射操作.

注意布隆算法，即使映射函数全部命中bitMap，也不一定数据就实际存在。因此可以升级布谷鸟过滤器，或者再查询数据库不存在之后，更新key.



###3.雪崩

某一时刻比如0:00 大量key失效。并发大时，这些查询压力全部涌入数据库

解决方案:

如果不是业务需要特定的某一时刻失效，可以设置key的随机过期时间,,避免key在某一时刻同时失效

热点数据设置永不过期

如果业务需要在特定的某一时刻失效，指定的时间之后，一次允许一个请求查询数据库，更新Redis，其他请求全部睡眠2,3秒后，再访问Redis.

